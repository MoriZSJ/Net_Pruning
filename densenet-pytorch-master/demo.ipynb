{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import densenet as dn\n",
    "import pdb\n",
    "# used for logging to TensorBoard\n",
    "from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = dn.DenseNet3(100, 4, 24, reduction=args.reduce,bottleneck=args.bottleneck, dropRate=args.droprate, small_inputs = False)\n",
    "parser = argparse.ArgumentParser(description='PyTorch DenseNet Training')\n",
    "parser.add_argument('--epochs', default=510, type=int,\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=500, type=int,\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=5, type=int,\n",
    "                    help='mini-batch size (default: 32)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    help='print frequency (default: 10)')\n",
    "parser.add_argument('--layers', default=100, type=int,\n",
    "                    help='total number of layers (default: 100)')\n",
    "parser.add_argument('--growth', default=12, type=int,\n",
    "                    help='number of new channels per layer (default: 12)')\n",
    "parser.add_argument('--droprate', default=0, type=float,\n",
    "                    help='dropout probability (default: 0.0)')\n",
    "parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
    "                    help='whether to use standard augmentation (default: False)')\n",
    "parser.add_argument('--reduce', default=0.5, type=float,\n",
    "                    help='compression rate in transition stage (default: 0.5)')\n",
    "parser.add_argument('--no-bottleneck', dest='bottleneck', action='store_false',\n",
    "                    help='To not use bottleneck block')\n",
    "parser.add_argument('--resume', default='C:\\\\Users\\\\fs\\\\Desktop\\\\densenet-pytorch-master\\\\runs_k=12\\\\DenseNet_Unet_fs\\\\model_best.pth', type=str,\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='DenseNet_Unet_fs', type=str,\n",
    "                    help='name of experiment')\n",
    "parser.add_argument('--tensorboard',\n",
    "                    help='Log progress to TensorBoard', action='store_true')\n",
    "parser.set_defaults(bottleneck=True)\n",
    "parser.set_defaults(augment=False)\n",
    "global args, best_prec1\n",
    "args = parser.parse_args([])\n",
    "val_dirs = 'C:\\\\Users\\\\fs\\\\Desktop\\\\densenet-pytorch-master\\\\testimg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),    \n",
    "        normalize,\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:\\Users\\fs\\Desktop\\densenet-pytorch-master\\runs_k=12\\DenseNet_Unet_fs\\model_best.pth'\n",
      "=> loaded checkpoint 'C:\\Users\\fs\\Desktop\\densenet-pytorch-master\\runs_k=12\\DenseNet_Unet_fs\\model_best.pth' (epoch 296)\n"
     ]
    }
   ],
   "source": [
    "model = dn.DenseNet3(100, 4, 12, bottleneck=args.bottleneck,  small_inputs = False)\n",
    "model = model.cuda()\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1626, 13.5673, -7.3540, -2.0392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Prediction:  flaw\n",
      "Wall time: 67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img = Image.open('.\\\\testimg\\\\num4.png')\n",
    "if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "transform_i = transforms.Compose([    \n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "            ])\n",
    "input = transform_i(img)\n",
    "input = input.unsqueeze(0)\n",
    "input = input.cuda()\n",
    "input = torch.autograd.Variable(input)\n",
    "model.eval()\n",
    "output = model(input)\n",
    "print(output)\n",
    "x= torch.max(output,1)\n",
    "classes = []\n",
    "with open('classes.txt', 'r') as list_:\n",
    "    for line in list_:\n",
    "        classes.append(line.rstrip('\\n'))\n",
    "\n",
    "print('Prediction: ', str(classes[x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = Image.open('.\\\\testimg\\\\flaw.jpg')\n",
    "ii = img.crop((100,150,200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.2650, -1.9809, -2.6503, -2.6371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Prediction:  bubble\n"
     ]
    }
   ],
   "source": [
    "input = input.unsqueeze(0)\n",
    "input = input.cuda()\n",
    "input = torch.autograd.Variable(input)\n",
    "\n",
    "output = model(input)\n",
    "print(output)\n",
    "x= torch.max(output,1)\n",
    "classes = []\n",
    "with open('classes.txt', 'r') as list_:\n",
    "    for line in list_:\n",
    "        classes.append(line.rstrip('\\n'))\n",
    "\n",
    "print('Prediction: ', str(classes[x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([1, 3, 200, 200])\n",
      "tensor([[ 7.2650, -1.9809, -2.6503, -2.6371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Prediction:  bubble\n",
      "Wall time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img = cv2.imread('bubble(3).bmp').astype(np.float32)\n",
    "#img = cv2.imread('bubble(2).bmp').astype(np.float32)\n",
    "img.shape\n",
    "img = np.transpose(img, axes=[2, 0, 1])\n",
    "\n",
    "#img = np.expand_dims(img, axis=0)\n",
    "print(type(img))\n",
    "transform_t = transforms.Compose([    \n",
    "        normalize,\n",
    "            ])\n",
    "#type(input)\n",
    "inputim = torch.from_numpy(img)\n",
    "inputim1 = transform_t(inputim/255)\n",
    "inputim1 = inputim1.unsqueeze(0)\n",
    "inputim1 = inputim1.cuda()\n",
    "inputim1 = torch.autograd.Variable(inputim1)\n",
    "print(inputim1.shape)\n",
    "\n",
    "#model.eval()\n",
    "output = model(inputim1)\n",
    "print(output)\n",
    "x= torch.max(output,1)\n",
    "classes = []\n",
    "with open('classes.txt', 'r') as list_:\n",
    "    for line in list_:\n",
    "        classes.append(line.rstrip('\\n'))\n",
    "\n",
    "print('Prediction: ', str(classes[x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "        val_dirs,\n",
    "        transform_train)   \n",
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        #datasets.CIFAR10('../data', train=False, transform=transform_test),\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fs\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "C:\\Users\\fs\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda(async=True)\n",
    "        print(type(input))\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

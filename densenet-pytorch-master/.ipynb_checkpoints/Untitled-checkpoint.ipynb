{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import densenet as dn\n",
    "import pdb\n",
    "# used for logging to TensorBoard\n",
    "from tensorboard_logger import configure, log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = dn.DenseNet3(100, 4, 24, reduction=args.reduce,bottleneck=args.bottleneck, dropRate=args.droprate, small_inputs = False)\n",
    "parser = argparse.ArgumentParser(description='PyTorch DenseNet Training')\n",
    "parser.add_argument('--epochs', default=510, type=int,\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=500, type=int,\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=16, type=int,\n",
    "                    help='mini-batch size (default: 32)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    help='print frequency (default: 10)')\n",
    "parser.add_argument('--layers', default=100, type=int,\n",
    "                    help='total number of layers (default: 100)')\n",
    "parser.add_argument('--growth', default=12, type=int,\n",
    "                    help='number of new channels per layer (default: 12)')\n",
    "parser.add_argument('--droprate', default=0, type=float,\n",
    "                    help='dropout probability (default: 0.0)')\n",
    "parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
    "                    help='whether to use standard augmentation (default: False)')\n",
    "parser.add_argument('--reduce', default=0.5, type=float,\n",
    "                    help='compression rate in transition stage (default: 0.5)')\n",
    "parser.add_argument('--no-bottleneck', dest='bottleneck', action='store_false',\n",
    "                    help='To not use bottleneck block')\n",
    "parser.add_argument('--resume', default='C:\\\\Users\\\\fs\\\\Desktop\\\\densenet-pytorch-master\\\\runs_k=12\\\\DenseNet_Unet_fs\\\\model_best.pth', type=str,\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='DenseNet_Unet_fs', type=str,\n",
    "                    help='name of experiment')\n",
    "parser.add_argument('--tensorboard',\n",
    "                    help='Log progress to TensorBoard', action='store_true')\n",
    "parser.set_defaults(bottleneck=True)\n",
    "parser.set_defaults(augment=False)\n",
    "global args, best_prec1\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            normalize,\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:\\Users\\fs\\Desktop\\densenet-pytorch-master\\runs_k=12\\DenseNet_Unet_fs\\model_best.pth'\n",
      "=> loaded checkpoint 'C:\\Users\\fs\\Desktop\\densenet-pytorch-master\\runs_k=12\\DenseNet_Unet_fs\\model_best.pth' (epoch 296)\n"
     ]
    }
   ],
   "source": [
    "model = dn.DenseNet3(100, 4, 12, bottleneck=args.bottleneck,  small_inputs = False)\n",
    "model = model.cuda()\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#img = cv2.imread('flaw.jpg')\n",
    "img = cv2.imread('bubble(9).bmp').astype(np.float32)\n",
    "img.shape\n",
    "img = np.transpose(img, axes=[2, 0, 1])\n",
    "\n",
    "#img = np.expand_dims(img, axis=0)\n",
    "img.shape\n",
    "\n",
    "#type(input)\n",
    "input = torch.from_numpy(img)\n",
    "input = transform_train(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5082.2334,  6692.0347, -3067.8418,  1459.7487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Prediction:  flaw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = input.unsqueeze(0)\n",
    "input = input.cuda()\n",
    "input = torch.autograd.Variable(input)\n",
    "input.shape\n",
    "\n",
    "model.eval()\n",
    "output = model(input)\n",
    "print(output)\n",
    "x= torch.max(output,1)\n",
    "classes = []\n",
    "with open('classes.txt', 'r') as list_:\n",
    "    for line in list_:\n",
    "        classes.append(line.rstrip('\\n'))\n",
    "\n",
    "print('Prediction: ', str(classes[x[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topk=(1,)\n",
    "maxk = max(topk)\n",
    "_, pred = output.topk(maxk, 1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pred.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
